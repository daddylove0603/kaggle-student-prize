{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\nfrom tqdm import tqdm\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n#         print(os.path.join(dirname, filename))\n        pass\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2021-12-21T12:00:02.885649Z","iopub.execute_input":"2021-12-21T12:00:02.885944Z","iopub.status.idle":"2021-12-21T12:00:04.465589Z","shell.execute_reply.started":"2021-12-21T12:00:02.885914Z","shell.execute_reply":"2021-12-21T12:00:04.464684Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_df = pd.read_csv('/kaggle/input/feedback-prize-2021/train.csv')","metadata":{"execution":{"iopub.status.busy":"2021-12-21T12:00:04.470031Z","iopub.execute_input":"2021-12-21T12:00:04.470651Z","iopub.status.idle":"2021-12-21T12:00:05.262241Z","shell.execute_reply.started":"2021-12-21T12:00:04.470608Z","shell.execute_reply":"2021-12-21T12:00:05.261269Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_df.shape","metadata":{"execution":{"iopub.status.busy":"2021-12-21T12:00:05.263802Z","iopub.execute_input":"2021-12-21T12:00:05.264130Z","iopub.status.idle":"2021-12-21T12:00:05.273641Z","shell.execute_reply.started":"2021-12-21T12:00:05.264086Z","shell.execute_reply":"2021-12-21T12:00:05.272676Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_df.columns","metadata":{"execution":{"iopub.status.busy":"2021-12-21T12:00:05.276641Z","iopub.execute_input":"2021-12-21T12:00:05.277603Z","iopub.status.idle":"2021-12-21T12:00:05.288861Z","shell.execute_reply.started":"2021-12-21T12:00:05.277557Z","shell.execute_reply":"2021-12-21T12:00:05.287757Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_names, test_texts = [], []\nfor f in tqdm(list(os.listdir('../input/feedback-prize-2021/test'))):\n    test_names.append(f.replace('.txt', ''))\n    test_texts.append(open('../input/feedback-prize-2021/test/' + f, 'r').read())\ntest_texts = pd.DataFrame({'id': test_names, 'text': test_texts})\n# test_texts['text'] = test_texts['text'].apply(lambda x:x.split())\ntest_texts.head()","metadata":{"execution":{"iopub.status.busy":"2021-12-21T12:00:05.290696Z","iopub.execute_input":"2021-12-21T12:00:05.291194Z","iopub.status.idle":"2021-12-21T12:00:05.343346Z","shell.execute_reply.started":"2021-12-21T12:00:05.291148Z","shell.execute_reply":"2021-12-21T12:00:05.342416Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_names, train_texts = [], []\nfor f in tqdm(list(os.listdir('../input/feedback-prize-2021/train'))):\n    test_names.append(f.replace('.txt', ''))\n    train_texts.append(open('../input/feedback-prize-2021/train/' + f, 'r').read())\ntrain_text_df = pd.DataFrame({'id': test_names, 'text': train_texts})\n# train_texts['text'] = test_texts['text'].apply(lambda x:x.split())\ntrain_text_df.head()","metadata":{"execution":{"iopub.status.busy":"2021-12-21T12:00:05.345038Z","iopub.execute_input":"2021-12-21T12:00:05.345650Z","iopub.status.idle":"2021-12-21T12:00:56.891601Z","shell.execute_reply.started":"2021-12-21T12:00:05.345605Z","shell.execute_reply":"2021-12-21T12:00:56.890619Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Convert predictionstring and discourse_type as a labels for NER\n\nI balanced number of words and ner labels at the end as there were some discrepancies with number of words and labells-- Might have to look how efficiently handle them later ","metadata":{}},{"cell_type":"code","source":"all_entities = []\nfor i in tqdm(train_text_df.iterrows()):\n    total = i[1]['text'].split(' ').__len__()\n    start = -1\n    entities = []\n    for j in train_df[train_df['id'] == i[1]['id']].iterrows():\n        discourse = j[1]['discourse_type']\n        list_ix = j[1]['predictionstring'].split(' ')\n#         print(j[1]['predictionstring'],'###' ,len(list_ix))\n        ent = [f\"I-{discourse}\" for ix in list_ix]\n        ent[0] = f\"B-{discourse}\"\n        ds = int(list_ix[0])\n        de = int(list_ix[-1])\n        if start < ds-1:\n            ent_add = ['O' for ix in range(int(ds-1-start))]\n            ent = ent_add + ent\n#         print(len(entities))\n#         print(ent, len(ent))\n        entities.extend(ent)\n#         print(len(entities))\n        start = de\n    if len(entities) < total:\n        ent_add = [\"O\" for ix in range(total-len(entities))]\n        entities += ent_add\n    else:\n        entities = entities[:total]\n#     print(i[1]['id'],'@@@@@@@@' ,i[1]['text'].split(' ').__len__(), len(entities))\n    all_entities.append(entities)\n#     if len(all_entities) > 100:\n#         break","metadata":{"execution":{"iopub.status.busy":"2021-12-21T12:00:56.892970Z","iopub.execute_input":"2021-12-21T12:00:56.894557Z","iopub.status.idle":"2021-12-21T12:06:30.864138Z","shell.execute_reply.started":"2021-12-21T12:00:56.894511Z","shell.execute_reply":"2021-12-21T12:06:30.863102Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_text_df['entities'] = all_entities","metadata":{"execution":{"iopub.status.busy":"2021-12-21T12:06:30.866164Z","iopub.execute_input":"2021-12-21T12:06:30.866631Z","iopub.status.idle":"2021-12-21T12:06:31.239741Z","shell.execute_reply.started":"2021-12-21T12:06:30.866588Z","shell.execute_reply":"2021-12-21T12:06:31.238642Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_text_df.head() ## for each text mapped corresponding entities","metadata":{"execution":{"iopub.status.busy":"2021-12-21T12:06:31.241434Z","iopub.execute_input":"2021-12-21T12:06:31.242287Z","iopub.status.idle":"2021-12-21T12:06:31.268019Z","shell.execute_reply.started":"2021-12-21T12:06:31.242220Z","shell.execute_reply":"2021-12-21T12:06:31.267109Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from transformers import RobertaTokenizerFast, RobertaForTokenClassification\nfrom torch.utils.data import Dataset, DataLoader\nimport pdb\nimport torch\nfrom torch import cuda\nfrom sklearn.metrics import accuracy_score","metadata":{"execution":{"iopub.status.busy":"2021-12-21T12:06:31.272874Z","iopub.execute_input":"2021-12-21T12:06:31.274568Z","iopub.status.idle":"2021-12-21T12:06:40.605083Z","shell.execute_reply.started":"2021-12-21T12:06:31.274480Z","shell.execute_reply":"2021-12-21T12:06:40.603975Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"config = {'model_name': '/kaggle/input/roberta-base/',\n         'max_length': 512,\n         'train_batch_size':8,\n         'valid_batch_size':16,\n         'epochs':3,\n         'learning_rate':1e-05,\n         'max_grad_norm':10,\n         'device': 'cuda' if cuda.is_available() else 'cpu'}","metadata":{"execution":{"iopub.status.busy":"2021-12-21T12:06:40.606934Z","iopub.execute_input":"2021-12-21T12:06:40.607383Z","iopub.status.idle":"2021-12-21T12:06:40.663348Z","shell.execute_reply.started":"2021-12-21T12:06:40.607314Z","shell.execute_reply":"2021-12-21T12:06:40.661648Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Mapping of labels and ids","metadata":{}},{"cell_type":"code","source":"output_labels = ['O', 'B-Lead', 'I-Lead', 'B-Position', 'I-Position', 'B-Claim', 'I-Claim', 'B-Counterclaim', 'I-Counterclaim', \n          'B-Rebuttal', 'I-Rebuttal', 'B-Evidence', 'I-Evidence', 'B-Concluding Statement', 'I-Concluding Statement']\n\nlabels_to_ids = {v:k for k,v in enumerate(output_labels)}\nids_to_labels = {k:v for k,v in enumerate(output_labels)}","metadata":{"execution":{"iopub.status.busy":"2021-12-21T12:06:40.667533Z","iopub.execute_input":"2021-12-21T12:06:40.667886Z","iopub.status.idle":"2021-12-21T12:06:40.683419Z","shell.execute_reply.started":"2021-12-21T12:06:40.667840Z","shell.execute_reply":"2021-12-21T12:06:40.682409Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"labels_to_ids","metadata":{"execution":{"iopub.status.busy":"2021-12-21T12:06:40.685079Z","iopub.execute_input":"2021-12-21T12:06:40.685570Z","iopub.status.idle":"2021-12-21T12:06:40.697020Z","shell.execute_reply.started":"2021-12-21T12:06:40.685524Z","shell.execute_reply":"2021-12-21T12:06:40.696001Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Define the dataset\nMake sure you take care of sub-tokenizing word problem when mapping tokens to labels","metadata":{}},{"cell_type":"code","source":"class dataset(Dataset):\n  def __init__(self, dataframe, tokenizer, max_len):\n        self.len = len(dataframe)\n        self.data = dataframe\n        self.tokenizer = tokenizer\n        self.max_len = max_len\n\n  def __getitem__(self, index):\n        # step 1: get the sentence and word labels \n        sentence = self.data.text[index]\n        word_labels = self.data.entities[index]\n\n        # step 2: use tokenizer to encode sentence (includes padding/truncation up to max length)\n        # BertTokenizerFast provides a handy \"return_offsets_mapping\" functionality for individual tokens\n        encoding = self.tokenizer(sentence,\n#                              is_pretokenized=True, \n#                                   is_split_into_words=True,\n                             return_offsets_mapping=True, \n                             padding='max_length', \n                             truncation=True, \n                             max_length=self.max_len)\n        \n        # step 3: create token labels only for first word pieces of each tokenized word\n#         pdb.set_trace()\n        labels = [labels_to_ids[label] for label in word_labels] \n        # code based on https://huggingface.co/transformers/custom_datasets.html#tok-ner\n        # create an empty array of -100 of length max_length\n        encoded_labels = np.ones(len(encoding[\"offset_mapping\"]), dtype=int) * -100\n#         print(len(sentence), len(labels))\n        # set only labels whose first offset position is 0 and the second is not 0\n        i = 0\n        for idx, mapping in enumerate(encoding[\"offset_mapping\"]):\n#             print(idx)\n            if mapping[0] != 0 and mapping[0] != encoding['offset_mapping'][idx-1][1]:\n            # overwrite label\n#             pdb.set_trace()\n#             print(mapping)\n#             print(encoded_labels.shape, len(labels), idx, i)\n                try:\n                    encoded_labels[idx] = labels[i]\n                except:\n                    pass\n                i += 1\n            else:\n                if idx==1:\n    #                 print(idx)\n                    encoded_labels[idx] = labels[i]\n                    i += 1\n        # step 4: turn everything into PyTorch tensors\n        item = {key: torch.as_tensor(val) for key, val in encoding.items()}\n        item['labels'] = torch.as_tensor(encoded_labels)\n        \n        return item\n\n  def __len__(self):\n        return self.len","metadata":{"execution":{"iopub.status.busy":"2021-12-21T12:06:40.698754Z","iopub.execute_input":"2021-12-21T12:06:40.699113Z","iopub.status.idle":"2021-12-21T12:06:40.714913Z","shell.execute_reply.started":"2021-12-21T12:06:40.699070Z","shell.execute_reply":"2021-12-21T12:06:40.713882Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"tokenizer = RobertaTokenizerFast.from_pretrained(config['model_name'])\nmodel = RobertaForTokenClassification.from_pretrained(config['model_name'], num_labels=len(output_labels))","metadata":{"execution":{"iopub.status.busy":"2021-12-21T12:06:40.716395Z","iopub.execute_input":"2021-12-21T12:06:40.716934Z","iopub.status.idle":"2021-12-21T12:06:47.651633Z","shell.execute_reply.started":"2021-12-21T12:06:40.716889Z","shell.execute_reply":"2021-12-21T12:06:47.650739Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Creating train test split and putting data into data loders","metadata":{}},{"cell_type":"code","source":"data = train_text_df[['text', 'entities']]\ntrain_size = 0.8\ntrain_dataset = data.sample(frac=train_size,random_state=200)\ntest_dataset = data.drop(train_dataset.index).reset_index(drop=True)\ntrain_dataset = train_dataset.reset_index(drop=True)\n\nprint(\"FULL Dataset: {}\".format(data.shape))\nprint(\"TRAIN Dataset: {}\".format(train_dataset.shape))\nprint(\"TEST Dataset: {}\".format(test_dataset.shape))\n\ntraining_set = dataset(train_dataset, tokenizer, config['max_length'])\ntesting_set = dataset(test_dataset, tokenizer, config['max_length'])","metadata":{"execution":{"iopub.status.busy":"2021-12-21T12:06:47.653471Z","iopub.execute_input":"2021-12-21T12:06:47.653818Z","iopub.status.idle":"2021-12-21T12:06:47.681208Z","shell.execute_reply.started":"2021-12-21T12:06:47.653775Z","shell.execute_reply":"2021-12-21T12:06:47.679300Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_params = {'batch_size': config['train_batch_size'],\n                'shuffle': True,\n                'num_workers': 1,\n                'pin_memory':True\n                }\n\ntest_params = {'batch_size': config['valid_batch_size'],\n                'shuffle': True,\n                'num_workers': 1,\n                'pin_memory':True\n                }\n\ntraining_loader = DataLoader(training_set, **train_params)\ntesting_loader = DataLoader(testing_set, **test_params)","metadata":{"execution":{"iopub.status.busy":"2021-12-21T12:06:47.683060Z","iopub.execute_input":"2021-12-21T12:06:47.683409Z","iopub.status.idle":"2021-12-21T12:06:47.689997Z","shell.execute_reply.started":"2021-12-21T12:06:47.683344Z","shell.execute_reply":"2021-12-21T12:06:47.688835Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_texts_set = dataset(test_texts, tokenizer, config['max_length'])\ntest_texts_loader = DataLoader(test_texts_set, **test_params)","metadata":{"execution":{"iopub.status.busy":"2021-12-21T12:06:47.692125Z","iopub.execute_input":"2021-12-21T12:06:47.692831Z","iopub.status.idle":"2021-12-21T12:06:47.701949Z","shell.execute_reply.started":"2021-12-21T12:06:47.692785Z","shell.execute_reply":"2021-12-21T12:06:47.700717Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# i=0\n# for token, label in zip(tokenizer.convert_ids_to_tokens(training_set[0][\"input_ids\"]), training_set[0][\"labels\"]):\n#     print(training_set[0]['offset_mapping'][i], '@@@')\n#     if label == -100:\n#         print('{}  {}'.format(token, label))\n#     else:\n#         print('{}  {}'.format(token, ids_to_labels[int(label)]))\n#     i+=1","metadata":{"execution":{"iopub.status.busy":"2021-12-21T12:06:47.704639Z","iopub.execute_input":"2021-12-21T12:06:47.704925Z","iopub.status.idle":"2021-12-21T12:06:47.712381Z","shell.execute_reply.started":"2021-12-21T12:06:47.704894Z","shell.execute_reply":"2021-12-21T12:06:47.710863Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Testing to make sure all shapes are correct and model able to run without errors","metadata":{}},{"cell_type":"code","source":"device = config['device']","metadata":{"execution":{"iopub.status.busy":"2021-12-21T12:06:47.714758Z","iopub.execute_input":"2021-12-21T12:06:47.715239Z","iopub.status.idle":"2021-12-21T12:06:47.723576Z","shell.execute_reply.started":"2021-12-21T12:06:47.715191Z","shell.execute_reply":"2021-12-21T12:06:47.722677Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.to(device)\ninputs = training_set[2]\ninput_ids = inputs[\"input_ids\"].unsqueeze(0)\nattention_mask = inputs[\"attention_mask\"].unsqueeze(0)\nlabels = inputs[\"labels\"].unsqueeze(0)\n\ninput_ids = input_ids.to(device)\nattention_mask = attention_mask.to(device)\nlabels = labels.to(device)\n\noutputs = model(input_ids, attention_mask=attention_mask, labels=labels,\n               return_dict=False)\ninitial_loss = outputs[0]\ninitial_loss","metadata":{"execution":{"iopub.status.busy":"2021-12-21T12:06:47.724963Z","iopub.execute_input":"2021-12-21T12:06:47.725533Z","iopub.status.idle":"2021-12-21T12:06:53.978379Z","shell.execute_reply.started":"2021-12-21T12:06:47.725489Z","shell.execute_reply":"2021-12-21T12:06:53.977271Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"optimizer = torch.optim.Adam(params=model.parameters(), lr=config['learning_rate'])","metadata":{"execution":{"iopub.status.busy":"2021-12-21T12:06:53.979885Z","iopub.execute_input":"2021-12-21T12:06:53.980439Z","iopub.status.idle":"2021-12-21T12:06:53.987365Z","shell.execute_reply.started":"2021-12-21T12:06:53.980396Z","shell.execute_reply":"2021-12-21T12:06:53.986165Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Defining the training function on the 80% of the dataset for tuning the bert model\ndef train(epoch):\n    tr_loss, tr_accuracy = 0, 0\n    nb_tr_examples, nb_tr_steps = 0, 0\n    tr_preds, tr_labels = [], []\n    # put model in training mode\n    model.train()\n    \n    for idx, batch in enumerate(training_loader):\n        \n        ids = batch['input_ids'].to(device, dtype = torch.long)\n        mask = batch['attention_mask'].to(device, dtype = torch.long)\n        labels = batch['labels'].to(device, dtype = torch.long)\n\n        loss, tr_logits = model(input_ids=ids, attention_mask=mask, labels=labels,\n                               return_dict=False)\n        tr_loss += loss.item()\n\n        nb_tr_steps += 1\n        nb_tr_examples += labels.size(0)\n        \n        if idx % 100==0:\n            loss_step = tr_loss/nb_tr_steps\n            print(f\"Training loss per 100 training steps: {loss_step}\")\n           \n        # compute training accuracy\n        flattened_targets = labels.view(-1) # shape (batch_size * seq_len,)\n        active_logits = tr_logits.view(-1, model.num_labels) # shape (batch_size * seq_len, num_labels)\n        flattened_predictions = torch.argmax(active_logits, axis=1) # shape (batch_size * seq_len,)\n        \n        # only compute accuracy at active labels\n        active_accuracy = labels.view(-1) != -100 # shape (batch_size, seq_len)\n        #active_labels = torch.where(active_accuracy, labels.view(-1), torch.tensor(-100).type_as(labels))\n        \n        labels = torch.masked_select(flattened_targets, active_accuracy)\n        predictions = torch.masked_select(flattened_predictions, active_accuracy)\n        \n        tr_labels.extend(labels)\n        tr_preds.extend(predictions)\n\n        tmp_tr_accuracy = accuracy_score(labels.cpu().numpy(), predictions.cpu().numpy())\n        tr_accuracy += tmp_tr_accuracy\n    \n        # gradient clipping\n        torch.nn.utils.clip_grad_norm_(\n            parameters=model.parameters(), max_norm=config['max_grad_norm']\n        )\n        \n        # backward pass\n        optimizer.zero_grad()\n        loss.backward()\n        optimizer.step()\n\n    epoch_loss = tr_loss / nb_tr_steps\n    tr_accuracy = tr_accuracy / nb_tr_steps\n    print(f\"Training loss epoch: {epoch_loss}\")\n    print(f\"Training accuracy epoch: {tr_accuracy}\")","metadata":{"execution":{"iopub.status.busy":"2021-12-21T12:06:53.989437Z","iopub.execute_input":"2021-12-21T12:06:53.990165Z","iopub.status.idle":"2021-12-21T12:06:54.029078Z","shell.execute_reply.started":"2021-12-21T12:06:53.990118Z","shell.execute_reply":"2021-12-21T12:06:54.027986Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for epoch in range(config['epochs']):\n    print(f\"Training epoch: {epoch + 1}\")\n    train(epoch)","metadata":{"execution":{"iopub.status.busy":"2021-12-21T12:06:54.031104Z","iopub.execute_input":"2021-12-21T12:06:54.031504Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def valid(model, testing_loader):\n    # put model in evaluation mode\n    model.eval()\n    \n    eval_loss, eval_accuracy = 0, 0\n    nb_eval_examples, nb_eval_steps = 0, 0\n    eval_preds, eval_labels = [], []\n    \n    with torch.no_grad():\n        for idx, batch in enumerate(testing_loader):\n            \n            ids = batch['input_ids'].to(device, dtype = torch.long)\n            mask = batch['attention_mask'].to(device, dtype = torch.long)\n            labels = batch['labels'].to(device, dtype = torch.long)\n            \n            loss, eval_logits = model(input_ids=ids, attention_mask=mask, labels=labels,\n                                     return_dict=False)\n            \n            eval_loss += loss.item()\n\n            nb_eval_steps += 1\n            nb_eval_examples += labels.size(0)\n        \n            if idx % 100==0:\n                loss_step = eval_loss/nb_eval_steps\n                print(f\"Validation loss per 100 evaluation steps: {loss_step}\")\n              \n            # compute evaluation accuracy\n            flattened_targets = labels.view(-1) # shape (batch_size * seq_len,)\n            active_logits = eval_logits.view(-1, model.num_labels) # shape (batch_size * seq_len, num_labels)\n            flattened_predictions = torch.argmax(active_logits, axis=1) # shape (batch_size * seq_len,)\n            \n            # only compute accuracy at active labels\n            active_accuracy = labels.view(-1) != -100 # shape (batch_size, seq_len)\n        \n            labels = torch.masked_select(flattened_targets, active_accuracy)\n            predictions = torch.masked_select(flattened_predictions, active_accuracy)\n            \n            eval_labels.extend(labels)\n            eval_preds.extend(predictions)\n            \n            tmp_eval_accuracy = accuracy_score(labels.cpu().numpy(), predictions.cpu().numpy())\n            eval_accuracy += tmp_eval_accuracy\n\n    labels = [ids_to_labels[id.item()] for id in eval_labels]\n    predictions = [ids_to_labels[id.item()] for id in eval_preds]\n    \n    eval_loss = eval_loss / nb_eval_steps\n    eval_accuracy = eval_accuracy / nb_eval_steps\n    print(f\"Validation Loss: {eval_loss}\")\n    print(f\"Validation Accuracy: {eval_accuracy}\")\n\n    return labels, predictions","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"labels, predictions = valid(model, testing_loader)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Inference function","metadata":{}},{"cell_type":"code","source":"sentence = \"@HuggingFace is a company based in New York, but is also has employees working in Paris\"\nmodel.eval()\ndef inference(sentence):\n    inputs = tokenizer(sentence,\n#                         is_split_into_words=True, \n                        return_offsets_mapping=True, \n                        padding='max_length', \n                        truncation=True, \n                        max_length=config['max_length'],\n                        return_tensors=\"pt\")\n\n    # move to gpu\n    ids = inputs[\"input_ids\"].to(device)\n    mask = inputs[\"attention_mask\"].to(device)\n    # forward pass\n    outputs = model(ids, attention_mask=mask, return_dict=False)\n    logits = outputs[0]\n\n    active_logits = logits.view(-1, model.num_labels) # shape (batch_size * seq_len, num_labels)\n    flattened_predictions = torch.argmax(active_logits, axis=1) # shape (batch_size*seq_len,) - predictions at the token level\n\n    tokens = tokenizer.convert_ids_to_tokens(ids.squeeze().tolist())\n    token_predictions = [ids_to_labels[i] for i in flattened_predictions.cpu().numpy()]\n    wp_preds = list(zip(tokens, token_predictions)) # list of tuples. Each tuple = (wordpiece, prediction)\n\n    prediction = []\n    out_str = []\n    off_list = inputs[\"offset_mapping\"].squeeze().tolist()\n    for idx, mapping in enumerate(off_list):\n#         print(mapping, token_pred[1], token_pred[0],\"####\")\n\n#         only predictions on first word pieces are important\n        if mapping[0] != 0 and mapping[0] != off_list[idx-1][1]:\n#             print(mapping, token_pred[1], token_pred[0])\n            prediction.append(wp_preds[idx][1])\n            out_str.append(wp_preds[idx][0])\n        else:\n            if idx == 1:\n                prediction.append(wp_preds[idx][1])\n                out_str.append(wp_preds[idx][0])\n            continue\n    return prediction, out_str","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_texts.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# test_texts = train_text_df['text'].tolist()[:10]\ny_pred = []\n\nfor i, t in enumerate(test_texts['text'].tolist()):\n    o,o_t = inference(t)\n    y_pred.append(o)\n    l = train_text_df['entities'][i]\n#     print(len(o), len(l), o,l, o_t)\n#     print(len(t.split(\" \")), len(o))\n#     max_len = 0\n#     if len(t.split()) < len(o_t):\n#         max_len = len(t.split())\n#     else:\n#         max_len = len(o_t)\n#     for ix in range(0, max_len, 10):\n#         print(t.split()[ix-10:ix], o_t[ix-10:ix],\n# #               l[ix-10:ix], o[ix-10:ix],\n#               '@@@@@@@')\n#     break","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### converting finally predicted labels into word index format as we got in training set","metadata":{}},{"cell_type":"code","source":"final_preds = []\nimport pdb\nfor i in tqdm(range(len(test_texts))):\n#     pdb.set_trace()\n    idx = test_texts.id.values[i]\n#     pred = ['']*len(test_texts[i])\n\n#     for j in range(len(y_pred[i])):\n#         if words[i][j] != None:\n#             pred[words[i][j]] = labels[y_pred[i][j]]\n\n    pred = [x.replace('B-','').replace('I-','') for x in y_pred[i]]\n#     print(pred)\n    preds = []\n    j = 0\n    while j < len(pred):\n        cls = pred[j]\n#         pdb.set_trace()\n        if cls == 'O':\n            j += 1\n        end = j + 1\n        while end < len(pred) and pred[end] == cls:\n            end += 1\n            \n        if cls != 'O' and cls != '' and end - j > 10:\n            final_preds.append((idx, cls, ' '.join(map(str, list(range(j, end))))))\n        \n        j = end\n        \nprint(final_preds[1])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"len(final_preds)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_df = pd.read_csv('../input/feedback-prize-2021/sample_submission.csv')\ntest_df","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sub = pd.DataFrame(final_preds)\nsub.columns = test_df.columns","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sub.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sub.to_csv(\"submission.csv\", index=False)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}